{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "DM_Assignment_3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/songseokbeom/ML_study/blob/master/Data_Mining/DM_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzgrcukyjqqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPpjI0eGjqqr",
        "colab_type": "text"
      },
      "source": [
        "# Wine dataset 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvFp5cIijqqr",
        "colab_type": "code",
        "outputId": "eb347a42-3b1c-45fb-928c-9cb0c3d42a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wine = load_wine()\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(wine.data, wine.target, random_state=777, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(142, 13)\n",
            "(36, 13)\n",
            "(142,)\n",
            "(36,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P10LSPKEjqqw",
        "colab_type": "text"
      },
      "source": [
        "# Wine dataset (참고용)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7UDEH9wyjqqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
        "sy = pd.Series(wine.target, dtype=\"category\")\n",
        "sy = sy.cat.rename_categories(wine.target_names)\n",
        "df['class'] = sy\n",
        "print(wine.DESCR)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IygpDF5Fjqqz",
        "colab_type": "text"
      },
      "source": [
        "# # Problem 1\n",
        "ID3 Decision Tree classifier.\n",
        "- decision-tree-id3 패키지를 pip install을 통해 설치하시오.\n",
        "- 위의 train 데이터(X_train, Y_train)를 이용하여 ID3 classifier 모델을 학습시키시오.\n",
        "- 위의 test 데이터(X_test, Y_test)를 이용해 정확도를 측정 후 출력하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-TjSFZIjqqz",
        "colab_type": "code",
        "outputId": "88edf024-24dc-4464-d862-bc4e664404a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "##########Put your installation code here###############\n",
        "!pip install decision-tree-id3\n",
        "########################################################"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: decision-tree-id3 in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from decision-tree-id3) (0.22.2.post1)\n",
            "Requirement already satisfied: nose>=1.1.2 in /usr/local/lib/python3.6/dist-packages (from decision-tree-id3) (1.3.7)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from decision-tree-id3) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17->decision-tree-id3) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17->decision-tree-id3) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80UaceOvjqq2",
        "colab_type": "code",
        "outputId": "f54d5eb3-7153-452c-fa2e-a6cccd73156e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import id3\n",
        "\n",
        "ID3_model = None\n",
        "accuracy = None\n",
        "############# Put your code here ################\n",
        "def eval(model, X_test, Y_test):\n",
        "  Y_hat = model.predict(X_test)\n",
        "  return np.sum(np.where(Y_hat - Y_test==0, 1, 0)) / X_test.shape[0]\n",
        "\n",
        "ID3_model = Id3Estimator()\n",
        "ID3_model.fit(X_train, Y_train)\n",
        "accuracy = eval(ID3_model, X_test, Y_test)\n",
        "################################################# \n",
        "print('Test data prediction accuracy (ID3) : %f'%accuracy)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data prediction accuracy (ID3) : 0.944444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdT_0Xyhjqq5",
        "colab_type": "text"
      },
      "source": [
        "# # Problem 2\n",
        "CART decision Tree classifier.\n",
        "- scikit-learn의 decision tree는 CART 기반 구현체이다.\n",
        "- Problem 1과 같은 방법으로 CART classifier 모델을 학습시키고 test데이터의 정확도를 출력하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxGqA_x9jqq6",
        "colab_type": "code",
        "outputId": "5be9fa7e-723d-42b8-d967-81636da4dc7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "CART_model = None\n",
        "accuracy = None\n",
        "############# Put your code here ################\n",
        "CART_model = DecisionTreeClassifier()\n",
        "CART_model.fit(X_train, Y_train)\n",
        "accuracy = eval(CART_model, X_test, Y_test)      \n",
        "################################################# \n",
        "print('Test data prediction accuracy (CART) : %f'%accuracy)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data prediction accuracy (CART) : 0.944444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WscZp2Sjqq8",
        "colab_type": "text"
      },
      "source": [
        "# # Problem 3\n",
        "Random Forest classifier.\n",
        "- scikit-learn의 random forest 패키지를 이용하여 모델을 학습시키고 test데이터의 정확도를 출력하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejzMuTQQjqq9",
        "colab_type": "code",
        "outputId": "45da31b0-5339-40b6-d01a-825cb6e33f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "Random_Forest_model = None\n",
        "accuracy = None\n",
        "############# Put your code here ################\n",
        "Random_Forest_model = RandomForestClassifier()\n",
        "Random_Forest_model.fit(X_train, Y_train)\n",
        "accuracy = eval(Random_Forest_model, X_test, Y_test)       \n",
        "################################################# \n",
        "print('Test data prediction accuracy (Random Forest) : %f'%accuracy)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data prediction accuracy (Random Forest) : 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dv7mxAUjqq_",
        "colab_type": "text"
      },
      "source": [
        "# # Problem 4\n",
        "XGBoost classifier.\n",
        "- XGBoost 패키지를 pip install을 통해 설치하시오.\n",
        "- 패키지를 불러와 모델을 학습시키고 test데이터의 정확도를 출력하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YGGYH7SjqrA",
        "colab_type": "code",
        "outputId": "15cbb357-8dce-4719-b962-2a656b409147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "##########Put your installation code here###############\n",
        "!pip install xgboost\n",
        "########################################################"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DcE-NwbjqrC",
        "colab_type": "code",
        "outputId": "088f8503-0f7d-493a-a2a2-35447ec3ac50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "XGB_model = None\n",
        "accuracy = None\n",
        "############# Put your code here ################\n",
        "XGB_model = xgb.XGBClassifier(objective='multi:softmax', max_depth=4, num_class=3)\n",
        "XGB_model.fit(X_train, Y_train)\n",
        "accuracy = eval(XGB_model, X_train, Y_train)\n",
        "################################################# \n",
        "print('Test data prediction accuracy (XGBoost) : %f'%accuracy)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data prediction accuracy (XGBoost) : 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adc8A1pHjqrE",
        "colab_type": "text"
      },
      "source": [
        "# # Problem 5\n",
        "LightGBM classifier.\n",
        "- LighGBM 패키지를 pip install을 통해 설치하시오.\n",
        "- 패키지를 불러와 모델을 학습시키고 test데이터의 정확도를 출력하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl6d9pLHjqrE",
        "colab_type": "code",
        "outputId": "e2afe7c3-b96c-4497-e878-e02f9906372c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "##########Put your installation code here###############\n",
        "!pip install lightgbm\n",
        "########################################################"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.18.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXYjkUCNjqrI",
        "colab_type": "code",
        "outputId": "c17ab4b6-ccf9-4a61-a966-4cd9ab876996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "LGBM_model = None\n",
        "accuracy = None\n",
        "############# Put your code here ################\n",
        "LGBM_model = lgb.LGBMClassifier(objective='multiclass',\n",
        "                                num_class=3)\n",
        "LGBM_model.fit(X_train, Y_train)\n",
        "accuracy = eval(LGBM_model, X_test, Y_test)\n",
        "################################################# \n",
        "print('Test data prediction accuracy (LightGBM) : %f'%accuracy)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data prediction accuracy (LightGBM) : 0.944444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCcuZU1RjqrK",
        "colab_type": "text"
      },
      "source": [
        "# # Problem 6\n",
        "Naive Bayes classifier.\n",
        "- Scikit-learn의 Gaussian Naive Bayes classifier를 불러와 학습시키고, test데이터의 정확도를 출력하시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpPSLiRDjqrK",
        "colab_type": "code",
        "outputId": "2c23c630-b161-43cd-dbe3-9e09531c2d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "NB_model = None\n",
        "accuracy = None\n",
        "############# Put your code here ################\n",
        "NB_model = GaussianNB()\n",
        "NB_model.fit(X_train, Y_train)\n",
        "accuracy = eval(NB_model, X_test, Y_test)\n",
        "################################################# \n",
        "print('Test data prediction accuracy (NaiveBayes) : %f'%accuracy)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data prediction accuracy (NaiveBayes) : 0.972222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNJ-LfMEjqrM",
        "colab_type": "text"
      },
      "source": [
        "# # Problem 7\n",
        "Ensemble classifier.\n",
        "- 위의 6개의 모델(ID3, CART, Random Forest, XGBoost, LightGBM, Naive Bayes)을 이용하여 Voting(6개의 예측 label중 가장 많이 예측된 label을 최종 prediction label로 택하는것)방법으로 최종 label을 택한 뒤, 예측 정확도를 출력하시오.\n",
        "- Scikit-learn의 VotingClassifier 패키지를 사용하여 작성.\n",
        "- 위에서 학습시킨 모델 변수명 사용 가능."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcYNgcGFjqrN",
        "colab_type": "code",
        "outputId": "deb7b8a0-43a5-4a7f-fc73-215cb834dce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "ensemble_classifier = None\n",
        "accuracy = None\n",
        "############# Put your code here ################\n",
        "print(type(XGB_model))\n",
        "ensemble_classifier = VotingClassifier(estimators=[('CART', CART_model),\n",
        "                                                   ('Random Forest', Random_Forest_model),\n",
        "                                                   ('Naive Bayes', NB_model),\n",
        "                                                   ('ID3', ID3_model),\n",
        "                                                   ('LightGBM', LGBM_model),\n",
        "                                                   ('XGBoost', XGB_model)])\n",
        "ensemble_classifier.fit(X_train, Y_train)\n",
        "accuracy = eval(ensemble_classifier, X_test, Y_test)\n",
        "################################################# \n",
        "print('Test data prediction accuracy (Ensemble) : %f'%accuracy)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'xgboost.sklearn.XGBClassifier'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-0570fd153400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                    \u001b[0;34m(\u001b[0m\u001b[0;34m'LightGBM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLGBM_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                                    ('XGBoost', XGB_model)])\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mensemble_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m\"\"\"Get common fit operations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         if (self.weights is not None and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 raise ValueError(\n\u001b[1;32m    248\u001b[0m                     \"The estimator {} should be a {}.\".format(\n\u001b[0;32m--> 249\u001b[0;31m                         \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_estimator_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m                     )\n\u001b[1;32m    251\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: The estimator Id3Estimator should be a classifier."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX4AEZrcgSV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
